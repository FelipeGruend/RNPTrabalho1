{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos deste trabalho:\n",
    "- Se familiarizar com o ambiente Notebook e com Python\n",
    "- Implementar um perceptron simples, treiná-lo no conjunto de TREINO do CIFAR-10 e avaliá-lo no conjunto de TESTE (alvo: distinguir fotos de animais de meios de transporte)\n",
    "- Utilizar a função sigmóide e verificar seu efeito no treinamento e na avaliação\n",
    "- Modificar a metodologia para classificar cada classe individualmente (i.e. treinar 10 perceptrons, um para cada classe). Considerar: dado um exemplo, que passará por cada perceptron, como decidir qual é a classe dele?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os datasets\n",
    "\n",
    "dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True)\n",
    "\n",
    "dataset_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset_train), len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para tons de cinza\n",
    "\n",
    "# Treino\n",
    "grayscale_dataset_train = []\n",
    "for img,label in dataset_train:\n",
    "    category = classes[label]\n",
    "    gray_npimg = np.array(img.convert('L'))\n",
    "    grayscale_dataset_train.append((gray_npimg,category))\n",
    "    \n",
    "# Teste\n",
    "grayscale_dataset_test = []\n",
    "for img,label in dataset_test:\n",
    "    category = classes[label]\n",
    "    gray_npimg = np.array(img.convert('L'))\n",
    "    grayscale_dataset_test.append((gray_npimg,category))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar uma imagem\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image_index = 1\n",
    "label = grayscale_dataset_train[image_index][1]\n",
    "npimg = grayscale_dataset_train[image_index][0]\n",
    "\n",
    "plt.imshow(npimg, cmap='gray')\n",
    "plt.title(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para vetores 1D\n",
    "\n",
    "# Para pensar: por que a divisão por 255 no código abaixo?\n",
    "\n",
    "# A divisão por 255 é feita para normalizar os tons de cinza entre 0 e 1\n",
    "\n",
    "linear_dataset_train = []\n",
    "target_labels = ('plane', 'car', 'ship', 'truck')\n",
    "for img,category in grayscale_dataset_train:\n",
    "    linear_img = img.reshape(img.shape[0]*img.shape[1],1) / 255\n",
    "    if category in target_labels:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    linear_dataset_train.append((linear_img,label))\n",
    "    \n",
    "linear_dataset_test = []\n",
    "target_labels = ('plane', 'car', 'ship', 'truck')\n",
    "for img,category in grayscale_dataset_test:\n",
    "    linear_img = img.reshape(img.shape[0]*img.shape[1],1) / 255\n",
    "    if category in target_labels:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    linear_dataset_test.append((linear_img,label))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(linear_dataset_train[0][0])\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo o perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def perceptron(inputs, weights):\n",
    "    \n",
    "    # Definição do somatório dos produtos das entradas com os pesos \n",
    "    o = np.sum(inputs * weights)\n",
    "    \n",
    "    # Retorna o resultado do somatório aplicado à função sigmoid\n",
    "    y = sigmoid(o)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando o perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função avaliação\n",
    "def evaluate(weights,dataset):\n",
    "    # true positives, true negatives, false positives, false negatives\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for img, label in dataset:\n",
    "\n",
    "        # Adiciona o bias nas entradas\n",
    "        img = np.append(img, 1)\n",
    "        \n",
    "        # Pega a predição do perceptron\n",
    "        y = perceptron(img, weights)\n",
    "        \n",
    "        # Ativação em 0.5\n",
    "        if(y < 0.5):\n",
    "            y = 0\n",
    "        else:\n",
    "            y = 1\n",
    "        \n",
    "        # Se a predição é igual ao valor real\n",
    "        if y == label:\n",
    "            # Então testa se é tp ou tn\n",
    "            if y == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        # Senão testa se é fn ou fp\n",
    "        else:\n",
    "            if y == 0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "    # Acurácia\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    # Sensitividade\n",
    "    recall = tp/(tp+fn)\n",
    "    \n",
    "    # Especificidade\n",
    "    specificity = tn/(tn+fp)\n",
    "    \n",
    "    # Retorna as métricas\n",
    "    return accuracy, recall, specificity\n",
    "    \n",
    "# Função de atualização dos pesos do perceptron\n",
    "def update_weights(inputs, weights, y, t, neta):\n",
    "    return weights + neta * (t-y) * inputs * (y * (1-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização\n",
    "weights = (np.random.rand(1,size) - 0.5)[0]\n",
    "bias = (np.random.rand(1) - 0.5) \n",
    "weights = np.append(weights, bias)\n",
    "\n",
    "neta = 0.0001\n",
    "\n",
    "# Implemente o treino aqui (para separar as duas classes definidas)\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    np.random.shuffle(linear_dataset_train)\n",
    "    \n",
    "    # Para cada exemplo do dataset\n",
    "    for example, target in linear_dataset_train:\n",
    "        \n",
    "        # Adiciona o bias nas entradas do exemplo\n",
    "        example = np.append(example, 1)\n",
    "        \n",
    "        # Passa as entradas do exemplo e os pesos para o perceptron\n",
    "        y = perceptron(example, weights)\n",
    "        \n",
    "        # Atualiza os pesos\n",
    "        weights = update_weights(example, weights, y, target, neta)\n",
    "    \n",
    "    # Calcula as métricas de avaliação para a época\n",
    "    accuracy, recall, specificity = evaluate(weights,linear_dataset_train)\n",
    "    # Exibe-as na tela\n",
    "    print('Época:', epoch, 'Acurácia:', accuracy, 'Sensitividade', recall, 'Especificidade:', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalie o modelo treinado aqui\n",
    "# Como a acurácia no conjunto de teste se compara com a acurácia obtida no conjunto de treino?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso queiram plotar alguma coisa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificando classes individuais\n",
    "\n",
    "Implemente aqui a modificação do processo de avaliação e treinamento para poder classificar cada classe individualmente.\n",
    "\n",
    "- Ideia geral: treinar um perceptron por classe (exemplo positivo = exemplos da classe; exemplos negativos = exemplo de todas outras classes)\n",
    "- Dado um exemplo qualquer, como decidir qual perceptron está dando a classe correta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
